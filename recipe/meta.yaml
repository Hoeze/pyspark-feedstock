{% set version = "3.2.0" %}

package:
  name: pyspark
  version: {{ version }}

source:
  # PyPI has had issues recently with timely releases due to size constraints of tarball;
  # Building from source runs into StackOverflow errors in CF CI; --> use upstream binary
  url: https://dist.apache.org/repos/dist/release/spark/spark-{{ version }}/pyspark-{{ version }}.tar.gz
  sha256: bfea06179edbfb4bc76a0f470bd3c38e12f00e1023e3ad0373558d07cff102ab
  patches:
    - 0001-Disable-symlinks-on-Windows.patch

build:
  noarch: python
  number: 0
  script: '{{ PYTHON }} -m pip install . --no-deps --ignore-installed -vv '

requirements:
  host:
    - pip
    - python
    - setuptools
  run:
    - numpy >=1.14
    - pandas >=0.23.2
    - py4j ==0.10.9
    - pyarrow >=1.0.0
    - python >=3.6

test:
  commands:
    - pip check
    - bash -c "compgen -c spark && compgen -c pyspark"  # [not win]
    - where *spark*                                     # [win]
  imports:
    - pyspark
    - pyspark.cloudpickle
    - pyspark.ml
    - pyspark.ml.linalg
    - pyspark.ml.param
    - pyspark.mllib
    - pyspark.mllib.linalg
    - pyspark.mllib.stat
    - pyspark.pandas
    - pyspark.pandas.data_type_ops
    - pyspark.pandas.indexes
    - pyspark.pandas.missing
    - pyspark.pandas.plot
    - pyspark.pandas.spark
    - pyspark.pandas.typedef
    - pyspark.pandas.usage_logging
    - pyspark.python.pyspark
    - pyspark.python.lib
    - pyspark.sql
    - pyspark.sql.avro
    - pyspark.sql.pandas
    - pyspark.streaming
    - pyspark.bin
    - pyspark.sbin
    - pyspark.jars
    - pyspark.data
    - pyspark.licenses
    - pyspark.resource
  requires:
    - pip

about:
  home: http://spark.apache.org/
  license: Apache-2.0
  # Not yet available in the pypi release
  license_file: {{ environ["RECIPE_DIR"] }}/LICENSE.txt
  summary: Apache Spark
  description: Apache Spark is a fast and general engine for large-scale data processing.

extra:
  recipe-maintainers:
    - parente
    - quasiben
    - dbast
    - mariusvniekerk
